{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyse Exploratoire et Détection d'Anomalies avec DBSCAN\n",
        "\n",
        "Ce notebook présente une analyse complète des données patients et l'application de l'algorithme DBSCAN pour la détection d'anomalies médicales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importation des bibliothèques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ajouter le répertoire parent au path\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Modules du projet\n",
        "from src.data_loader import load_patient_data, validate_required_columns\n",
        "from src.preprocessing import clean_data, prepare_features, normalize_features\n",
        "from src.dbscan_model import (\n",
        "    compute_k_distance_curve,\n",
        "    plot_k_distance_curve,\n",
        "    suggest_eps_from_k_distance,\n",
        "    apply_dbscan\n",
        ")\n",
        "from src.visualization import plot_clusters_2d, plot_feature_distributions, plot_cluster_statistics\n",
        "\n",
        "# Configuration\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chargement des données\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_FILE = '../data/patients.csv'\n",
        "PATIENT_ID_COL = 'patient_id'\n",
        "FEATURE_COLS = [\n",
        "    'blood_pressure_systolic',\n",
        "    'blood_pressure_diastolic',\n",
        "    'temperature_c',\n",
        "    'heart_rate_bpm'\n",
        "]\n",
        "\n",
        "df = load_patient_data(DATA_FILE)\n",
        "validate_required_columns(df, [PATIENT_ID_COL] + FEATURE_COLS)\n",
        "\n",
        "print(f\"\\nShape: {df.shape}\")\n",
        "print(f\"\\nPremières lignes:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Analyse Exploratoire des Données (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== INFORMATIONS GÉNÉRALES ===\")\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== STATISTIQUES DESCRIPTIVES ===\")\n",
        "df[FEATURE_COLS].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== DISTRIBUTION DES VARIABLES ===\")\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, col in enumerate(FEATURE_COLS):\n",
        "    axes[idx].hist(df[col].values, bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "    axes[idx].set_title(f'Distribution: {col}', fontweight='bold')\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].set_ylabel('Fréquence')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Nettoyage et Préprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = clean_data(df, patient_id_col=PATIENT_ID_COL)\n",
        "X, patient_ids = prepare_features(df_clean, FEATURE_COLS, PATIENT_ID_COL)\n",
        "X_scaled, scaler = normalize_features(X)\n",
        "\n",
        "print(f\"Features préparées: {X_scaled.shape}\")\n",
        "print(f\"Moyenne après normalisation: {X_scaled.mean(axis=0)}\")\n",
        "print(f\"Écart-type après normalisation: {X_scaled.std(axis=0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Détermination des Paramètres DBSCAN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MIN_SAMPLES = 5\n",
        "k_distances = compute_k_distance_curve(X_scaled, k=MIN_SAMPLES)\n",
        "plot_k_distance_curve(k_distances, k=MIN_SAMPLES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Suggestion automatique de eps\n",
        "eps_suggested = suggest_eps_from_k_distance(k_distances, percentile=50.0)\n",
        "print(f\"\\nValeur eps suggérée (médiane): {eps_suggested:.4f}\")\n",
        "\n",
        "# Vous pouvez aussi tester différentes valeurs\n",
        "eps_candidates = [\n",
        "    np.percentile(k_distances, 25),\n",
        "    np.percentile(k_distances, 50),\n",
        "    np.percentile(k_distances, 75)\n",
        "]\n",
        "print(f\"\\nCandidats eps (25%, 50%, 75%): {[f'{e:.4f}' for e in eps_candidates]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Application de DBSCAN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPS = eps_suggested  # Utiliser la valeur suggérée ou ajuster manuellement\n",
        "\n",
        "labels, dbscan_model = apply_dbscan(X_scaled, eps=EPS, min_samples=MIN_SAMPLES)\n",
        "\n",
        "# Ajouter les labels au DataFrame\n",
        "df_clean['cluster_label'] = labels\n",
        "df_clean['is_anomaly'] = (labels == -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualisations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_clusters_2d(X_scaled, labels, method='pca')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_feature_distributions(df_clean, FEATURE_COLS, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_cluster_statistics(labels)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
